{"cells":[{"cell_type":"markdown","metadata":{"id":"1zELv6rHAdaa"},"source":["# Agente de Datos"]},{"cell_type":"markdown","metadata":{"id":"QLW0vHGsADJQ"},"source":["- Jesús Alexander Meister Careaga A01656699              \n","- Iker Bali Elizalde Iker A01656437\n","- Michelle Aguirre Martínez A01661592\n","- Diego Sánchez Hernández A01783237\n","- Maricarmen Daniela Barillas Duarte A01369993"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv('BimboCsv.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from langchain_ollama.llms import OllamaLLM\n","from langchain_core.prompts import ChatPromptTemplate\n","from pandas import DataFrame"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class DataAgent:\n","    def __init__(self, df:DataFrame) -> None:\n","\n","        model_name = 'llama3.2'\n","        self.df = df\n","\n","        self.memory = []\n","\n","        self.df_llm = OllamaLLM(model=model_name, temperature=0)\n","        self.df_template = \"\"\"\n","        Historial de conversación: {memory}\n","        Estructura del DataFrame: {df_structure}\n","        Pregunta: {question}\n","        Nombre de la variable del DataFrame: df\n","        Respuesta: Por favor, proporciona solamente el código de Python necesario para resolver la pregunta basada en la estructura del DataFrame de Pandas proporcionada, \n","        debes guardar la respuesta en una variable llamada resultado, sin imprimir nada. Recuerda importar las librerias que sean necesarias.\n","        En caso de requerir multiples respuestas, incluyelas en un diccionario llamado resultado.\n","        No me expliques nada, no incluyas '''pyton''' ni nada de eso. Solamente codigo ejecutable. \n","        Nunca, bajo ninguna circunstancia me des algo así: ```python [codigo] ```, solamente el codigo sin nada más.\n","        \"\"\"\n","        self.df_prompt = ChatPromptTemplate.from_template(self.df_template)\n","        self.df_chain = self.df_prompt | self.df_llm\n","\n","        self.humanize_llm = OllamaLLM(model=model_name, temperature=0)\n","        self.humanize_template = \"\"\"\n","        Historial de conversación: {memory}\n","        Pregunta: {question}\n","        Resultado: {result}\n","        Estructura del DataFrame: {df_structure}\n","        Contexto: Previamente, se calculó el resultado a una pregunta sobre un dataframe con la estructura proporcionada. \n","        Eres un asistente digital amigable llamado Bimbot, tu trabajo es darle un formato humano al resultado.\n","        Respuesta: Por favor, escribe como un humano lo haría para responder la pregunta hecha previamente, basandote en el resultado obtenido.\n","        \"\"\"\n","        self.humanize_prompt = ChatPromptTemplate.from_template(self.humanize_template)\n","        self.humanize_chain = self.humanize_prompt | self.humanize_llm\n","\n","    def add_to_memory(self, question, result):\n","        self.memory.append({'pregunta':question, 'resultado':result})\n","\n","    def get_code(self, question):\n","        res = self.df_chain.invoke({            \n","            'df_structure': self.df.dtypes,\n","            'question': question,\n","            'memory': self.memory\n","        })\n","        return res\n","    \n","    def get_result(self, code):\n","        context = {'df': self.df.copy()}\n","        try:\n","            exec(code, context)\n","            return context['resultado']\n","        except Exception as e:\n","            return f'Ocurrió un error al ejecutar el codigo: {e} | Intentar otra instrucción'\n","    \n","    def humanize_result(self, question, result):\n","        res = self.humanize_chain.invoke({\n","            'question': question,\n","            'result': result,\n","            'df_structure': self.df.dtypes,\n","            'memory': self.memory\n","        })\n","        return res\n","    \n","    def ask_question(self, question):\n","        code = self.get_code(question)\n","        print(code)\n","        result = self.get_result(code)\n","        self.add_to_memory(question, result)\n","        human_result = self.humanize_result(question, result)\n","        return human_result"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import sys\n","from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget, QTextEdit, QLineEdit, QPushButton\n","\n","class ChatBotUI(QMainWindow):\n","    def __init__(self, data_agent:DataAgent):\n","        super().__init__()\n","        self.data_agent = data_agent\n","        self.initUI()\n","\n","    def initUI(self):\n","        self.setWindowTitle('ChatBot - Bimbo Style')\n","        self.setGeometry(100, 100, 800, 600)\n","\n","        central_widget = QWidget()\n","        self.setCentralWidget(central_widget)\n","\n","        layout = QVBoxLayout(central_widget)\n","\n","        self.chat_display = QTextEdit()\n","        self.chat_display.setReadOnly(True)\n","        self.chat_display.append(f'<b>Bimbot:</b> ¡Hola!, soy el osito Bimbot, tu asistente digital de inventario, ¿en qué puedo ayudarte?')\n","        self.chat_display.append('')\n","        layout.addWidget(self.chat_display)\n","\n","        self.input_field = QLineEdit()\n","        layout.addWidget(self.input_field)\n","\n","        self.send_button = QPushButton('Enviar')\n","        self.send_button.clicked.connect(self.send_message)\n","        layout.addWidget(self.send_button)\n","\n","        self.setStyleSheet(open('style.css').read())\n","\n","    def send_message(self):\n","        user_message = self.input_field.text()\n","        if user_message:\n","            self.chat_display.append(f'<b>Usuario:</b> {user_message}')\n","            self.chat_display.append('')\n","            response = self.data_agent.ask_question(user_message)\n","            self.chat_display.append(f'<b>Bimbot:</b> {response}')\n","            self.chat_display.append('')\n","            self.input_field.clear()\n","\n","\n","def run_app():\n","    app = QApplication(sys.argv)\n","    data_agent = DataAgent(df)\n","    ex = ChatBotUI(data_agent)\n","    ex.show()\n","    app.exec_()\n","\n","if __name__ == '__main__':\n","    run_app()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
