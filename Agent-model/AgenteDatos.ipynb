{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from langchain_ollama.llms import OllamaLLM\n","from langchain_core.prompts.chat import ChatPromptTemplate"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class Memory:\n","    def __init__(self) -> None:\n","        self.memory = []\n","    \n","    def add(self, new_memory):\n","        self.memory.append(new_memory)\n","\n","        if len(self.memory) > 4:\n","            self.memory.pop(0)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class DataAgent:\n","    def __init__(self, df) -> None:\n","\n","        model_name = 'llama3.2'\n","        self.df = df\n","\n","        self.memory = Memory()\n","\n","        self.df_llm = OllamaLLM(model=model_name, temperature=0)\n","        self.df_template = \"\"\"\n","        Historial de conversación: {memory}\n","        Estructura del DataFrame: {df_structure}\n","        Pregunta: {question}\n","        Nombre de la variable del DataFrame: df\n","        Respuesta: Por favor, proporciona solamente el código de Python necesario para resolver la pregunta basada en la estructura del DataFrame de Pandas proporcionada, \n","        debes guardar la respuesta en una variable llamada resultado, sin imprimir nada.\n","        En caso de requerir multiples respuestas, incluyelas en un diccionario llamado resultado.\n","        No me expliques nada, no incluyas '''pyton''' ni nada de eso. Solamente codigo ejecutable. \n","        Nunca, bajo ninguna circunstancia me des algo así: ```python [codigo] ```, solamente el codigo sin nada más.\n","        \"\"\"\n","        self.df_prompt = ChatPromptTemplate.from_template(self.df_template)\n","        self.df_chain = self.df_prompt | self.df_llm\n","\n","        self.humanize_llm = OllamaLLM(model=model_name, temperature=0)\n","        self.humanize_template = \"\"\"\n","        Historial de conversación: {memory}\n","        Pregunta: {question}\n","        Resultado: {result}\n","        Estructura del DataFrame: {df_structure}\n","        Contexto: Previamente, se calculó el resultado a una pregunta sobre un dataframe con la estructura proporcionada. \n","        Eres un asistente digital amigable llamado Bimbot, tu trabajo es darle un formato humano al resultado.\n","        Responde solamente basandote en el resultado obtenido.\n","        Respuesta: Por favor, escribe como un humano lo haría para responder la pregunta hecha previamente, basandote en el resultado obtenido.\n","        \"\"\"\n","        self.humanize_prompt = ChatPromptTemplate.from_template(self.humanize_template)\n","        self.humanize_chain = self.humanize_prompt | self.humanize_llm\n","\n","    def add_to_memory(self, question, result):\n","        self.memory.add({'pregunta':question, 'resultado':result})\n","\n","    def get_code(self, question):\n","        res = self.df_chain.invoke({            \n","            'df_structure': self.df.dtypes,\n","            'question': question,\n","            'memory': self.memory\n","        })\n","        return res\n","    \n","    def get_result(self, code):\n","        context = {'df': self.df.copy()}\n","        try:\n","            exec(code, context)\n","            return context['resultado']\n","        except Exception as e:\n","            return f'Ocurrió un error al ejecutar el codigo: {e} | Intentar otra instrucción'\n","    \n","    def humanize_result(self, question, result):\n","        res = self.humanize_chain.invoke({\n","            'question': question,\n","            'result': result,\n","            'df_structure': self.df.dtypes,\n","            'memory': self.memory\n","        })\n","        return res\n","    \n","    def ask_question(self, question):\n","        code = self.get_code(question)\n","        print(code)\n","        result = self.get_result(code)\n","        print(result)\n","        self.add_to_memory(question, result)\n","        human_result = self.humanize_result(question, result)\n","        return human_result"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-04 21:53:17.912 python[73212:3566031] +[IMKClient subclass]: chose IMKClient_Legacy\n","2024-11-04 21:53:17.912 python[73212:3566031] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"]}],"source":["import sys\n","from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget, QTextEdit, QLineEdit, QPushButton\n","\n","class ChatBotUI(QMainWindow):\n","    def __init__(self, data_agent:DataAgent):\n","        super().__init__()\n","        self.data_agent = data_agent\n","        self.initUI()\n","\n","    def initUI(self):\n","        self.setWindowTitle('Bimbot Chat')\n","        self.setGeometry(100, 100, 800, 600)\n","\n","        central_widget = QWidget()\n","        self.setCentralWidget(central_widget)\n","\n","        layout = QVBoxLayout(central_widget)\n","\n","        self.chat_display = QTextEdit()\n","        self.chat_display.setReadOnly(True)\n","        self.chat_display.append(f'<b>Bimbot:</b> ¡Hola!, soy el osito Bimbot, tu asistente digital de inventario, ¿en qué puedo ayudarte?')\n","        self.chat_display.append('')\n","        layout.addWidget(self.chat_display)\n","\n","        self.input_field = QLineEdit()\n","        layout.addWidget(self.input_field)\n","\n","        self.send_button = QPushButton('Enviar')\n","        self.send_button.clicked.connect(self.send_message)\n","        layout.addWidget(self.send_button)\n","\n","        self.setStyleSheet(open('style.css').read())\n","\n","    def send_message(self):\n","        user_message = self.input_field.text()\n","        if user_message:\n","            self.chat_display.append(f'<b>Usuario:</b> {user_message}')\n","            self.chat_display.append('')\n","            response = self.data_agent.ask_question(user_message)\n","            self.chat_display.append(f'<b>Bimbot:</b> {response}')\n","            self.chat_display.append('')\n","            self.input_field.clear()\n","\n","\n","def run_app():\n","    df = pd.read_excel('CC.xlsx')\n","    app = QApplication(sys.argv)\n","    data_agent = DataAgent(df)\n","    ex = ChatBotUI(data_agent)\n","    ex.show()\n","    app.exec_()\n","\n","if __name__ == '__main__':\n","    run_app()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ProyectoBimbo","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
