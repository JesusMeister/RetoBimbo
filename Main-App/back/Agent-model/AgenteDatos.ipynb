{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from langchain_ollama.llms import OllamaLLM\n","from langchain_core.prompts.chat import ChatPromptTemplate\n","from langchain_huggingface import HuggingFaceEndpoint"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class Memory:\n","    def __init__(self) -> None:\n","        self.memory = []\n","    \n","    def add(self, new_memory):\n","        self.memory.append(new_memory)\n","\n","        if len(self.memory) > 2:\n","            self.memory.pop(0)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class DataAgent:\n","    def __init__(self, df) -> None:\n","\n","        model_name = 'llama3.2'\n","        self.df = df\n","\n","        self.memory = Memory()\n","\n","        self.df_llm = OllamaLLM(model=model_name, temperature=0)\n","        self.df_template = \"\"\"\n","        Historial de conversación: {memory}\n","        Estructura del DataFrame: {df_structure}\n","        Pregunta: {question}\n","        Nombre de la variable del DataFrame: df\n","        Respuesta: Por favor, proporciona solamente el código de Python necesario para resolver la pregunta basada en la estructura del DataFrame de Pandas proporcionada, \n","        debes guardar la respuesta en una variable llamada resultado, sin imprimir nada.\n","        En caso de requerir multiples respuestas, incluyelas en un diccionario llamado resultado.\n","        No me expliques nada, no incluyas '''pyton''' ni nada de eso. Solamente codigo ejecutable. \n","        Nunca, bajo ninguna circunstancia me des algo así: ```python [codigo] ```, solamente el codigo sin nada más.\n","        \"\"\"\n","        self.df_prompt = ChatPromptTemplate.from_template(self.df_template)\n","        self.df_chain = self.df_prompt | self.df_llm\n","\n","        self.humanize_llm = OllamaLLM(model=model_name, temperature=0)\n","        self.humanize_template = \"\"\"\n","        Historial de conversación: {memory}\n","        Pregunta: {question}\n","        Resultado: {result}\n","        Estructura del DataFrame: {df_structure}\n","        Contexto: Previamente, se calculó el resultado a una pregunta sobre un dataframe con la estructura proporcionada. \n","        Eres un asistente digital amigable llamado Bimbot, tu trabajo es darle un formato humano al resultado.\n","        Responde solamente basandote en el resultado obtenido.\n","        Respuesta: Por favor, escribe como un humano lo haría para responder la pregunta hecha previamente, basandote en el resultado obtenido.\n","        \"\"\"\n","        self.humanize_prompt = ChatPromptTemplate.from_template(self.humanize_template)\n","        self.humanize_chain = self.humanize_prompt | self.humanize_llm\n","\n","    def add_to_memory(self, question, result):\n","        self.memory.add(f'|Pregunta: {question}, Respuesta: {result}|')\n","\n","    def get_code(self, question):\n","        res = self.df_chain.invoke({            \n","            'df_structure': self.df.dtypes,\n","            'question': question,\n","            'memory': self.memory.memory\n","        })\n","        return res\n","    \n","    def get_result(self, code):\n","        context = {'df': self.df.copy()}\n","        try:\n","            exec(code, context)\n","            return context['resultado']\n","        except Exception as e:\n","            return f'Ocurrió un error al ejecutar el codigo: {e} | Intentar otra instrucción'\n","    \n","    def humanize_result(self, question, result):\n","        res = self.humanize_chain.invoke({\n","            'question': question,\n","            'result': result,\n","            'df_structure': self.df.dtypes,\n","            'memory': self.memory.memory\n","        })\n","        return res\n","    \n","    def ask_question(self, question):\n","        code = self.get_code(question)\n","        print(code)\n","        result = self.get_result(code)\n","        print(result)\n","        print(self.memory.memory)\n","        human_result = self.humanize_result(question, result)\n","        self.add_to_memory(question, result)\n","        return human_result"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","path = '../../../Utils/CC.xlsx'\n","x = pd.read_excel(path)\n","x = x[x['Descripcion de articulo'].notnull()]\n","articulos = x['Descripcion de articulo'].unique()\n","\n","np.random.seed(42)\n","num_rows = 250\n","data = {\n","    'Rack': [chr(np.random.randint(65, 91)) for _ in range(num_rows)],\n","    'Columna': np.random.randint(1, 53, size=num_rows),\n","    'Fila': np.random.randint(1, 4, size=num_rows),\n","    'Cantidad': np.random.randint(1, 49, size=num_rows),\n","    'Descripcion del articulo': np.random.choice(articulos, size=num_rows)\n","}\n","df = pd.DataFrame(data)\n","df\n","\n","def rack_to_number(rack_str):\n","    try:\n","        n = ord(rack_str.upper()) - ord('A') + 1\n","        return n\n","    except (AttributeError, TypeError):\n","      return\n","\n","df = df.drop_duplicates(subset=['Rack', 'Columna'])\n","df['n'] = df['Rack'].apply(rack_to_number)\n","df = df[df['n'] != 0]\n","df['Fila'] = df['Fila'].astype(int)\n","df['n'] = df['n'].astype(int)\n","df['Ubicacion'] = df['Rack'] + \"-\" + df['n'].astype(str) + \"-\" + df['Columna'].astype(str) + \"-\" + df['Fila'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:8080\n","\u001b[33mPress CTRL+C to quit\u001b[0m\n","127.0.0.1 - - [10/Nov/2024 00:44:18] \"OPTIONS /ask HTTP/1.1\" 200 -\n"]},{"name":"stdout","output_type":"stream","text":["{'question': 'Cual rack tiene mayor cantidad?'}\n","resultado = df.loc[df['Cantidad'].idxmax()]['Rack']\n","C\n","[]\n"]},{"name":"stderr","output_type":"stream","text":["127.0.0.1 - - [10/Nov/2024 00:44:23] \"POST /ask HTTP/1.1\" 200 -\n","127.0.0.1 - - [10/Nov/2024 00:44:29] \"OPTIONS /ask HTTP/1.1\" 200 -\n"]},{"name":"stdout","output_type":"stream","text":["{'question': 'Cuanta cantidad tiene ese rack?'}\n","resultado = df['Cantidad'].max()\n","48\n","['|Pregunta: Cual rack tiene mayor cantidad?, Respuesta: C|']\n"]},{"name":"stderr","output_type":"stream","text":["127.0.0.1 - - [10/Nov/2024 00:44:34] \"POST /ask HTTP/1.1\" 200 -\n","127.0.0.1 - - [10/Nov/2024 00:45:06] \"OPTIONS /ask HTTP/1.1\" 200 -\n"]},{"name":"stdout","output_type":"stream","text":["{'question': 'Cuanta cantidad tiene ese Rack en total?'}\n","resultado = df['Cantidad'].sum()\n","5636\n","['|Pregunta: Cual rack tiene mayor cantidad?, Respuesta: C|', '|Pregunta: Cuanta cantidad tiene ese rack?, Respuesta: 48|']\n"]},{"name":"stderr","output_type":"stream","text":["127.0.0.1 - - [10/Nov/2024 00:45:10] \"POST /ask HTTP/1.1\" 200 -\n"]}],"source":["from flask import Flask, request, jsonify\n","from flask_cors import CORS\n","\n","app = Flask(__name__)\n","CORS(app)\n","da = DataAgent(df)\n","\n","@app.route('/ask', methods=['POST'])\n","def ask_question():\n","    data = request.get_json()\n","    print(data)\n","    question = data.get('question')\n","    \n","    answer = da.ask_question(question)\n","    \n","    return jsonify({'answer': answer})\n","\n","if __name__ == '__main__':\n","    app.run(debug=False, port=8080)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ProyectoBimbo","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
